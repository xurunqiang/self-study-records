{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84de010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¡¨å¤´ï¼š0,1\n",
      "--------------------------------------------------------------------------------\n",
      "ç¬¬1è¡Œï¼šè¡¨æ¼” çš„ æ˜æ˜Ÿ æ˜¯ X å¥³å­© å›¢é˜Ÿ â€” â€” ç”± ä¸€å¯¹ å…·æœ‰ å¤©æ‰ æŠ€è‰º çš„ è‰³èˆ å¥³å­© ä»¬ ç»„æˆ ï¼Œ å…¶ä¸­ æœ‰äº› äºº å—è¿‡ ä¸“ä¸š çš„ è®­ç»ƒ ã€‚,\"the show stars the X Girls - a troupe of talented topless dancers , some of whom are classically trained .\"\n",
      "ç¬¬2è¡Œï¼šè¡¨æ¼” çš„ å‹è½´æˆ æ˜¯ é—¹å‰§ ç‰ˆ ã€Š å¤©é¹…æ¹– ã€‹ ï¼Œ ç”·å¥³ å° äººä»¬ èº«ç€ ç²‰çº¢è‰² çš„ èŠ­è•¾èˆ è£™ æ‰®æ¼” å°å¤©é¹… ã€‚,the centerpiece of the show is a farcical rendition of Swan Lake in which male and female performers dance in pink tutus and imitate swans .\n",
      "ç¬¬3è¡Œï¼šè¡¨æ¼” å’Œ åæœŸåˆ¶ä½œ ä¹‹é—´ çš„ å±éšœ è¢« æ¸…é™¤ äº† ï¼Œ è¿™ å¯¹ æ¼”å‘˜ æ¥è¯´ ä¸€æ · å¤§æœ‰è£¨ç›Š ã€‚,the removal of the barrier between performance and post @-@ production was just as helpful for the actors .\n",
      "ç¬¬4è¡Œï¼šï¼ˆ è¡¨æ¼” æˆ– èƒŒè¯µ æ—¶ ï¼‰ é€šè¿‡ æš—ç¤º ä¸‹é¢ å¿˜è®° æˆ– è®°åœ° ä¸å‡† çš„ ä¸œè¥¿ æ¥ å¸®åŠ© æŸäºº ã€‚,assist ( somebody acting or reciting ) by suggesting the next words of something forgotten or imperfectly learned .\n",
      "ç¬¬5è¡Œï¼šè¡¨æ¼” åŸºæœ¬ä¸Š å¾ˆ ç²¾å½© - - æˆ‘ åª å¯¹ å¥¹ çš„ æŠ€å·§ ç¨ æœ‰ æ„è§ ã€‚,basically it was a fine performance I have only minor quibbles to make about her technique .\n",
      "ç¬¬6è¡Œï¼šè¡¨æ¼” ç»“æŸ å ï¼Œ æˆ‘ä»¬ çœ‹åˆ° ä¸€å¯¹å¯¹ è½¦ç¯ æ²¿ä¸»è·¯ ä¸€è·¯ æ’å› é•‡ä¸Š ï¼Œ ç„¶å æ•£å¼€ æ¥ å„å› å„å®¶ ã€‚,\"after it &apos;s over , we watch the pairs of headlights glide in a neat line back up Main Street , dispersing as drivers turn off toward home .\"\n",
      "ç¬¬7è¡Œï¼šè¡¨æ¼” ç»“æŸ å ï¼Œ ç§»èµ° äº† èƒŒæ™¯å¢™ ï¼Œ éšå å…¨ä½“ æ¼”å‘˜ å³å…´ é‚€è¯· è§‚ä¼— ä¸Šå° é½ è·³ å¹¶æ’ èˆ ã€‚,after the performance they removed the back wall of the theatre and the cast summoned the audience onstage for an impromptu line dance .\n",
      "ç¬¬8è¡Œï¼šè¡¨æ¼” ç»“æŸ å ç”¨ å®£çº¸ è½»é“º æ°´é¢ ï¼Œ å¯ å°† æ°´é¢ ä¸Š çš„ ç”» è¿›è¡Œ æ‹“å° ä¿å­˜ ã€‚,\"after the end of each performance with paper can be spread the water , light on the surface were saved . kids draw .\"\n",
      "ç¬¬9è¡Œï¼šè¡¨æ¼” ç»“æŸ å ï¼Œ ä¼—äºº æœŸå¾…å·²ä¹… çš„ å›­æ¸¸ä¼š ç»ˆäº æ­£å¼ å¼€é”£ ï¼Œ ç¾å‘³å¯å£ çš„ ç´ é£Ÿ ä½³è‚´ è®© å¤§å®¶ ä¸€é¥±å£ç¦ ã€‚,\"after the performances , a garden party featuring delicious vegetarian food , which had been long awaited by many , finally began .\"\n",
      "ç¬¬10è¡Œï¼šè¡¨æ¼” èŠ‚ç›® ä¸°å¯Œ ç²¾é‡‡ ï¼Œ äº¤æ¢ ç¤¼ç‰© çš„ æ¬¢ä¹ æ—¶åˆ» ä¸€åˆ° ï¼Œ åˆ™ å½¢æˆ å¦ ä¸€æ³¢ é«˜æ½® ã€‚,\"the event featured a variety of spectacular performances , and was highlighted by the joyful exchange of special gifts .\"\n",
      "ç¬¬11è¡Œï¼šè¡¨æ¼” ä»…ä»… æ˜¯ é€ å°± ä¸€ä¸ª è¿‘ä¹ è§‰å¯Ÿ ä¸ å‡ºæ¥ çš„ ã€Œ ç›´çº¿ çš„ åœ°è´¨ çš„ ç§»ä½ ã€ ã€‚,the performance simply effected a near imperceptible &apos; linear geological displacement . &quot; &quot;\n",
      "ç¬¬12è¡Œï¼šè¡¨æ¼” å¼€å§‹ åäº”åˆ†é’Ÿ å ï¼Œ ä¸€å¸® è¶³çƒ è¿åŠ¨å‘˜ å¼€å§‹ é›†ä½“ å‘ç€ èˆå° ä¸Š çš„ å¥³æ¼”å‘˜ å‘å‡º å˜˜å£° ã€‚,\"fifteen minutes into the show , a bunch of rowdy football players started catcalling several actresses on stage .\"\n",
      "ç¬¬13è¡Œï¼šè¡¨æ¼” å¼€å§‹ æ—¶ ï¼Œ èˆå° ä¸Šä¼š æœ‰ ä¸€å¼  åºŠ ï¼Œ ä¸€é¢é•œå­ ï¼Œ ä¸€å¼  æ¤…å­ ä»¥åŠ ä¸€ä½ ç©¿ç€ å†…è¡£ çš„ ç¾å¥³ ã€‚ åœ¨ ä½  è§‰å¯Ÿåˆ° å‰ ï¼Œ ä¸€ä½ æ€§æ„Ÿ çš„ å¥³å­© ä¼š çªç„¶ å˜æˆ ä¸‰ä½ ã€‚,\"the show takes off with a bed , a mirror , a chair and one lingerie @-@ clad beauty and before you know it , one sexy lady becomes three .\"\n",
      "ç¬¬14è¡Œï¼šè¡¨æ¼” å¼€å§‹ æ—¶ ï¼Œ è‰ºäºº ååœ¨ åœ°æ¯¯ ä¸Š è½»å‡» ç›…å­ ï¼Œ å¾ç¼“ èµ·èˆ ï¼›,\"in the beginning , the performer sits on the carpet , beats the wine cups lightly and begins dancing slowly .\"\n",
      "ç¬¬15è¡Œï¼šè¡¨æ¼” â€œ çŒ« å¥³ â€ â€” â€” åœ¨ ä¸€ä¸ª ç¬¼å­ é‡Œ ç©¿ç€ å¸¦æœ‰ ä¸€æ ¹ é•¿å°¾å·´ å’Œ çŒ« è€³ çš„ è±¹çº¹ å¥³å†…è¡£ ã€‚,playing &quot; catwoman &quot; -- in leopard print lingerie with a long tail and cat ears while sitting in a cage .\n",
      "ç¬¬16è¡Œï¼šè¡¨æ¼” å‰ ï¼Œ å¥¹ ç´§å¼  å¾— æµ‘èº« é¢¤æŠ– ä¸å·² ã€‚,she was so nervous before the performance that she was shaking like a jelly .\n",
      "ç¬¬17è¡Œï¼šè¡¨æ¼” æ˜¯ ä»–ä»¬ çš„ å«¡ä¼  æŠ€è‰º ï¼Œ 150 å¤šå¹´ æ¥ ä»–ä»¬ å®¶æ— ä¸€ç›´ éƒ½ æ˜¯ æ¼”å‘˜ ã€‚,acting runs in their blood ; they have been actors for more than 150 years .\n",
      "ç¬¬18è¡Œï¼šè¡¨æ¼” ç®—å¾— ä¸Š æ˜¯ ä¸€é—¨ æ®‹å¿ çš„ èŒä¸š ï¼Œ ä½  åç¦» æ­£ç»Ÿ ç¾è¶Š è¿œ ï¼Œ å°± è¶Š è‰°éš¾ ã€‚,\"acting can be a brutal occupation , and it gets harder the further away you veer from the standard ideal of beauty .\"\n",
      "ç¬¬19è¡Œï¼šè¡¨æ¼” æˆ‘ è½¯æœ¨å¡ å“ªä¸€ å‘¼å¸ å’Œ æˆ‘ å°† è¡¨æ¼” ä½  ä¸€ç“¶ é†‹ ã€‚,show me a cork that breathes and I &apos;ll show you a bottle of vinegar .\n",
      "ç¬¬20è¡Œï¼šè¡¨æ¼” ï¼š æ‚‰å°¼æ­Œå‰§é™¢ é¦–å¸­ ç”·é«˜éŸ³ ä¸æ¯… å…ˆç”Ÿ æ‚‰å°¼æ­Œå‰§é™¢ é¦–å¸­ å¥³é«˜éŸ³,\"performers : Mr. Ding Yi , Chief tenor of Sydney Opera House Chief soprano of Sydney Opera House\"\n"
     ]
    }
   ],
   "source": [
    "def view_csv_head_native(file_path: str, n_rows: int = 20, encoding: str = \"utf-8\"):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=encoding) as f:\n",
    "            # è¯»å–è¡¨å¤´\n",
    "            header = f.readline().strip()\n",
    "            print(f\"è¡¨å¤´ï¼š{header}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            # è¯»å–å‰nè¡Œå†…å®¹\n",
    "            for i in range(n_rows):\n",
    "                line = f.readline()\n",
    "                if not line:  # æ–‡ä»¶ä¸è¶³100è¡Œæ—¶ç»ˆæ­¢\n",
    "                    break\n",
    "                print(f\"ç¬¬{i+1}è¡Œï¼š{line.strip()}\")\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"ç¼–ç é”™è¯¯ï¼Œå°è¯•GBKç¼–ç ...\")\n",
    "        view_csv_head_native(file_path, n_rows, encoding=\"gbk\")\n",
    "\n",
    "# è°ƒç”¨\n",
    "view_csv_head_native(r\"C:\\Users\\31392\\Desktop\\writebyhand\\wmt_data\\wmt_zh_en_training_corpus.csv\", n_rows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4af795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ æ–‡ä»¶å¤§å°ï¼š6064.67 MB\n",
      "ğŸ”¢ æ­£åœ¨ç»Ÿè®¡è¡Œæ•°...ï¼ˆè¶…å¤§æ–‡ä»¶å¯èƒ½éœ€è¦å‡ ç§’ï¼‰\n",
      "âœ… ç»Ÿè®¡å®Œæˆï¼\n",
      "ğŸ“Š CSVæ–‡ä»¶æ€»è¡Œæ•°ï¼ˆå«è¡¨å¤´ï¼‰ï¼š24752393\n",
      "ğŸ“Š æ•°æ®è¡Œæ•°ï¼ˆä¸å«è¡¨å¤´ï¼‰ï¼š24752392\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_csv_total_lines(file_path: str, encoding: str = \"utf-8\") -> int:\n",
    "    \"\"\"\n",
    "    ç»Ÿè®¡CSVæ–‡ä»¶æ€»è¡Œæ•°ï¼ˆé«˜æ•ˆç‰ˆï¼Œé€è¡Œè¯»å–ï¼Œä½å†…å­˜å ç”¨ï¼‰\n",
    "    :param file_path: CSVæ–‡ä»¶è·¯å¾„\n",
    "    :param encoding: æ–‡ä»¶ç¼–ç ï¼Œé»˜è®¤UTF-8\n",
    "    :return: æ€»è¡Œæ•°ï¼ˆåŒ…å«è¡¨å¤´ï¼‰\n",
    "    \"\"\"\n",
    "    # ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ â†’ {file_path}\")\n",
    "        return 0\n",
    "    \n",
    "    # ç¬¬äºŒæ­¥ï¼šé€è¡Œç»Ÿè®¡è¡Œæ•°\n",
    "    total_lines = 0\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=encoding) as f:\n",
    "            # å¯é€‰ï¼šæ˜¾ç¤ºæ–‡ä»¶å¤§å°ï¼Œè®©ä½ æœ‰é¢„æœŸ\n",
    "            file_size = os.path.getsize(file_path) / (1024 * 1024)  # è½¬æ¢ä¸ºMB\n",
    "            print(f\"ğŸ“„ æ–‡ä»¶å¤§å°ï¼š{file_size:.2f} MB\")\n",
    "            print(\"ğŸ”¢ æ­£åœ¨ç»Ÿè®¡è¡Œæ•°...ï¼ˆè¶…å¤§æ–‡ä»¶å¯èƒ½éœ€è¦å‡ ç§’ï¼‰\")\n",
    "            \n",
    "            # é€è¡Œè¯»å–ï¼Œç»Ÿè®¡è¡Œæ•°\n",
    "            for _ in f:\n",
    "                total_lines += 1\n",
    "                \n",
    "        print(f\"âœ… ç»Ÿè®¡å®Œæˆï¼\")\n",
    "        print(f\"ğŸ“Š CSVæ–‡ä»¶æ€»è¡Œæ•°ï¼ˆå«è¡¨å¤´ï¼‰ï¼š{total_lines}\")\n",
    "        print(f\"ğŸ“Š æ•°æ®è¡Œæ•°ï¼ˆä¸å«è¡¨å¤´ï¼‰ï¼š{total_lines - 1 if total_lines > 0 else 0}\")\n",
    "        return total_lines\n",
    "    \n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"âŒ é”™è¯¯ï¼š{encoding}ç¼–ç è§£æå¤±è´¥ï¼Œå°è¯•GBKç¼–ç é‡æ–°ç»Ÿè®¡...\")\n",
    "        # è‡ªåŠ¨é‡è¯•GBKç¼–ç ï¼ˆä¸­æ–‡Windowsæ–‡ä»¶å¸¸è§ï¼‰\n",
    "        return count_csv_total_lines(file_path, encoding=\"gbk\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æœªçŸ¥é”™è¯¯ï¼š{str(e)}\")\n",
    "        return 0\n",
    "\n",
    "# ------------------- æ ¸å¿ƒè°ƒç”¨ -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # æ›¿æ¢ä¸ºä½ çš„CSVæ–‡ä»¶å®é™…è·¯å¾„\n",
    "    csv_file_path = r\"C:\\Users\\31392\\Desktop\\writebyhand\\wmt_data\\wmt_zh_en_training_corpus.csv\"\n",
    "    \n",
    "    # ç»Ÿè®¡æ€»è¡Œæ•°\n",
    "    count_csv_total_lines(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0ad7bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SRC length stats (space-token count) ===\n",
      "{'count': 24752356, 'p50': 17.0, 'p90': 39.0, 'p95': 47.0, 'p99': 61.0, 'max': 80, 'mean': 19.793406130713375}\n",
      "\n",
      "=== TGT length stats (space-token count) ===\n",
      "{'count': 24752356, 'p50': 21.0, 'p90': 46.0, 'p95': 56.0, 'p99': 74.0, 'max': 155, 'mean': 23.971527276029803}\n",
      "\n",
      "=== Longest SRC ===\n",
      "len = 80\n",
      "æˆ‘ è§‰å¾— æˆ‘ ä¾ä» äº† ï¼Œ å¯ä»¥ å…å» å¦ ä¸€åœº ä¹±å­ ï¼› æˆ‘ ä¹Ÿ è®¤ä¸º ï¼Œ è¿™ ä¹Ÿè®¸ å¯ä»¥ åœ¨ å‡¯ç‘Ÿç³ çš„ å¿ƒç—… ä¸Š åˆ›é€  ä¸€ä¸ª æœ‰åˆ© çš„ è½¬æœº ï¼š åæ¥ æˆ‘ åˆ è®°èµ· åŸƒå¾·åŠ  å…ˆç”Ÿ ä¸¥å‰ è´£éª‚ æˆ‘ æ¬å¼„æ˜¯é ï¼› æˆ‘ åå¤ è‚¯å®š è¯´ é‚£æ¬¡ èƒŒä¿¡ å‘Šå¯† çš„ äº‹ ï¼Œ å¦‚æœ è¯¥å— è¿™æ · ç²—æš´ çš„ åç§° çš„è¯ ï¼Œ ä¹Ÿ è¯¥æ˜¯ æœ€å ä¸€æ¬¡ äº† ï¼Œ æˆ‘ å€Ÿ è¿™ä¸ª è‚¯å®š æ¥ æ¶ˆé™¤ æˆ‘ å¯¹äº è¿™äº‹ æ‰€ æ„Ÿåˆ° çš„ ä¸€åˆ‡ ä¸å®‰ ã€‚\n",
      "\n",
      "=== Longest TGT ===\n",
      "len = 155\n",
      "å§”å‘˜ä¼š å†³å®š è®¾ç«‹ ä¸€ä¸ª ç”± Awosika å…ˆç”Ÿ æ‹…ä»» ä¸»å¸­ çš„ ä¸é™ æˆå‘˜ åé¢ å·¥ä½œç»„ ( æˆå‘˜ åŒ…æ‹¬ Albuquerque å…ˆç”Ÿ ã€ Beltagy å…ˆç”Ÿ ã€ Betah å…ˆç”Ÿ ã€ Brekke å…ˆç”Ÿ ã€ Carrera å…ˆç”Ÿ ã€ Chan Chim Yuk å…ˆç”Ÿ ã€ Francis å…ˆç”Ÿ ã€ Hamuro å…ˆç”Ÿ ã€ Hinz å…ˆç”Ÿ ã€ Jaafar å…ˆç”Ÿ ã€ å•æ–‡æ­£ å…ˆç”Ÿ ã€ Park å…ˆç”Ÿ å’Œ Srinivasan å…ˆç”Ÿ ) , è´Ÿè´£ åœ¨ é—­ä¼š æœŸé—´ è‰æ‹Ÿ å…³äº...\n"
     ]
    }
   ],
   "source": [
    "import html\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def tokenize_space(text: str):\n",
    "    return [t for t in text.strip().split() if t]\n",
    "\n",
    "def load_pairs_from_csv_first_comma(path, max_rows=None):\n",
    "    path = Path(path)\n",
    "    pairs = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line_idx, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # è·³è¿‡è¡¨å¤´\n",
    "            if line_idx == 0:\n",
    "                head = line.replace('\"', \"\").replace(\" \", \"\")\n",
    "                if head == \"0,1\":\n",
    "                    continue\n",
    "\n",
    "            k = line.find(\",\")\n",
    "            if k == -1:\n",
    "                continue\n",
    "\n",
    "            src = line[:k].strip()\n",
    "            tgt = line[k+1:].strip()\n",
    "\n",
    "            # å»ä¸¤ä¾§å¼•å·ï¼ˆè‹¥æœ‰ï¼‰\n",
    "            if len(src) >= 2 and src[0] == '\"' and src[-1] == '\"':\n",
    "                src = src[1:-1].strip()\n",
    "            if len(tgt) >= 2 and tgt[0] == '\"' and tgt[-1] == '\"':\n",
    "                tgt = tgt[1:-1].strip()\n",
    "\n",
    "            src = html.unescape(src)\n",
    "            tgt = html.unescape(tgt)\n",
    "\n",
    "            if src and tgt:\n",
    "                pairs.append((src, tgt))\n",
    "\n",
    "            if max_rows is not None and len(pairs) >= max_rows:\n",
    "                break\n",
    "    return pairs\n",
    "\n",
    "def analyze_max_lengths(pairs, show_chars=200):\n",
    "    src_lens = []\n",
    "    tgt_lens = []\n",
    "    max_src = (-1, None)  # (len, text)\n",
    "    max_tgt = (-1, None)\n",
    "\n",
    "    for src, tgt in pairs:\n",
    "        s_len = len(tokenize_space(src))\n",
    "        t_len = len(tokenize_space(tgt))\n",
    "\n",
    "        src_lens.append(s_len)\n",
    "        tgt_lens.append(t_len)\n",
    "\n",
    "        if s_len > max_src[0]:\n",
    "            max_src = (s_len, src)\n",
    "        if t_len > max_tgt[0]:\n",
    "            max_tgt = (t_len, tgt)\n",
    "\n",
    "    src_arr = np.array(src_lens)\n",
    "    tgt_arr = np.array(tgt_lens)\n",
    "\n",
    "    def stats(arr):\n",
    "        return {\n",
    "            \"count\": int(arr.size),\n",
    "            \"p50\": float(np.percentile(arr, 50)),\n",
    "            \"p90\": float(np.percentile(arr, 90)),\n",
    "            \"p95\": float(np.percentile(arr, 95)),\n",
    "            \"p99\": float(np.percentile(arr, 99)),\n",
    "            \"max\": int(arr.max()),\n",
    "            \"mean\": float(arr.mean()),\n",
    "        }\n",
    "\n",
    "    print(\"=== SRC length stats (space-token count) ===\")\n",
    "    print(stats(src_arr))\n",
    "    print(\"\\n=== TGT length stats (space-token count) ===\")\n",
    "    print(stats(tgt_arr))\n",
    "\n",
    "    print(\"\\n=== Longest SRC ===\")\n",
    "    print(\"len =\", max_src[0])\n",
    "    print(max_src[1][:show_chars] + (\"...\" if len(max_src[1]) > show_chars else \"\"))\n",
    "\n",
    "    print(\"\\n=== Longest TGT ===\")\n",
    "    print(\"len =\", max_tgt[0])\n",
    "    print(max_tgt[1][:show_chars] + (\"...\" if len(max_tgt[1]) > show_chars else \"\"))\n",
    "\n",
    "    return {\n",
    "        \"src_lens\": src_arr,\n",
    "        \"tgt_lens\": tgt_arr,\n",
    "        \"max_src_len\": max_src[0],\n",
    "        \"max_tgt_len\": max_tgt[0],\n",
    "        \"max_src_text\": max_src[1],\n",
    "        \"max_tgt_text\": max_tgt[1],\n",
    "    }\n",
    "\n",
    "# ===== ç”¨æ³• 1ï¼šå¦‚æœä½ è¿˜æ²¡è¯»å…¨é‡ pairs =====\n",
    "csv_path = \"./wmt_data/wmt_zh_en_training_corpus.csv\"  # æ”¹æˆä½ çš„å®é™…è·¯å¾„\n",
    "pairs_all = load_pairs_from_csv_first_comma(csv_path)\n",
    "\n",
    "result = analyze_max_lengths(pairs_all, show_chars=240)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
